{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <h1> <b> Predict Essay Scores </b> </h1>  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <h3> Kuah Jia Chen  </h3>  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The objective of this assignment is to conduct predictive analytics, by using Support Vector Machine/ Regression with a dataset provided by using Python in the Jupyter Notebook environment. The dataset is “FIT1043-Essay-Features.csv”. The main purpose of this assignment is to make use of the dataset to predict the student's scores on essays based on their essay features. In order to achieve this, firstly, I would perform a train-test split, feature engineering, normalization, model fitting, and eventually evaluate the performance of the model created by using accuracy, quadratic weighted kappa, and confusion matrix. Afterward, the model created would be used to predict the essay score for another dataset and submit the result to Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Importing libraries\n",
    "3. Read “FIT1043-Essay-Features.csv”\n",
    "4. Questions related to Supervised Learning\n",
    "   * Explanation for supervised machine learning\n",
    "   * Explanation for the notion of labeled data\n",
    "   * Explanation for training and test datasets \n",
    "5. Feature Engineering\n",
    "6. Feature Selection\n",
    "7. Train-test split\n",
    "8. Questions related to Classification\n",
    "   * Explanation for the difference between binary and multi-class classification\n",
    "9. Normalization\n",
    "   * Describe the need for normalization\n",
    "   * Normalize the data\n",
    "1. Model creation\n",
    "   * Describe SVM in relation to Linear Regression\n",
    "   * Explanation for the kernel in SVM/SVR\n",
    "   * Build the model\n",
    "11. Predict\n",
    "12. Performance of the model\n",
    "13. Kaggle Submission\n",
    "14. Conclusion\n",
    "15. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import cohen_kappa_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read “FIT1043-Essay-Features.csv”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1457   2153    426      14            6             0         5.053991   \n",
       "1      503   1480    292       9            7             0         5.068493   \n",
       "2      253   3964    849      19           26             1         4.669022   \n",
       "3      107    988    210       8            7             0         4.704762   \n",
       "4     1450   3139    600      13            8             0         5.231667   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         16          0          26.625000  423.995272         0.995294   \n",
       "1         11          0          26.545455  290.993103         0.996552   \n",
       "2         49          2          17.326531  843.990544         0.994100   \n",
       "3         12          0          17.500000  207.653784         0.988828   \n",
       "4         24          1          25.000000  594.652150         0.991087   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           207                  0.485915            105   \n",
       "1           148                  0.506849             77   \n",
       "2           285                  0.335689            130   \n",
       "3           112                  0.533333             62   \n",
       "4           255                  0.425000            165   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                   0.246479        424      412      4  \n",
       "1                   0.263699        356      345      4  \n",
       "2                   0.153121        750      750      4  \n",
       "3                   0.295238        217      209      3  \n",
       "4                   0.275000        702      677      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EssayFeatures = pd.read_csv(r\"C:\\Users\\Andy Kuah Jia Chen\\Downloads\\FIT1043 Assignments\\Prediction-Of-Essay_Scores\\data\\FIT1043-Essay-Features.csv\")\n",
    "EssayFeatures.head() # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic descriptive statistics of the values in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EssayFeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that there are 1332 essays in total and 19 columns that contain the data which describe each essay's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essayid                        int64\n",
       "chars                          int64\n",
       "words                          int64\n",
       "commas                         int64\n",
       "apostrophes                    int64\n",
       "punctuations                   int64\n",
       "avg_word_length              float64\n",
       "sentences                      int64\n",
       "questions                      int64\n",
       "avg_word_sentence            float64\n",
       "POS                          float64\n",
       "POS/total_words              float64\n",
       "prompt_words                   int64\n",
       "prompt_words/total_words     float64\n",
       "synonym_words                  int64\n",
       "synonym_words/total_words    float64\n",
       "unstemmed                      int64\n",
       "stemmed                        int64\n",
       "score                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EssayFeatures.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear to see that the majority of the data types for the columns are integer, whereas only a few columns are float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>905.27027</td>\n",
       "      <td>2101.745495</td>\n",
       "      <td>424.485736</td>\n",
       "      <td>14.667417</td>\n",
       "      <td>8.141141</td>\n",
       "      <td>0.47973</td>\n",
       "      <td>4.939762</td>\n",
       "      <td>19.704204</td>\n",
       "      <td>1.222973</td>\n",
       "      <td>23.884687</td>\n",
       "      <td>420.596542</td>\n",
       "      <td>0.989935</td>\n",
       "      <td>198.913664</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>110.16967</td>\n",
       "      <td>0.263846</td>\n",
       "      <td>468.987988</td>\n",
       "      <td>455.507508</td>\n",
       "      <td>3.427177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>526.68760</td>\n",
       "      <td>865.963750</td>\n",
       "      <td>171.873730</td>\n",
       "      <td>10.920781</td>\n",
       "      <td>6.124520</td>\n",
       "      <td>1.27168</td>\n",
       "      <td>0.231071</td>\n",
       "      <td>19.202731</td>\n",
       "      <td>1.847446</td>\n",
       "      <td>11.160020</td>\n",
       "      <td>170.985111</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>82.729266</td>\n",
       "      <td>0.052466</td>\n",
       "      <td>43.96192</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>159.447449</td>\n",
       "      <td>155.751220</td>\n",
       "      <td>0.774275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.231322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084112</td>\n",
       "      <td>35.647059</td>\n",
       "      <td>0.924771</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.027299</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>442.75000</td>\n",
       "      <td>1527.250000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.791679</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>305.406284</td>\n",
       "      <td>0.987758</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.435709</td>\n",
       "      <td>81.00000</td>\n",
       "      <td>0.238423</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>350.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>914.50000</td>\n",
       "      <td>2029.500000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.946059</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.030331</td>\n",
       "      <td>406.982869</td>\n",
       "      <td>0.991572</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>0.465852</td>\n",
       "      <td>107.50000</td>\n",
       "      <td>0.262872</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1369.75000</td>\n",
       "      <td>2613.500000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.092938</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.048234</td>\n",
       "      <td>520.739458</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>134.00000</td>\n",
       "      <td>0.288277</td>\n",
       "      <td>581.000000</td>\n",
       "      <td>561.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1799.00000</td>\n",
       "      <td>6142.000000</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>5.681429</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1158.984563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>355.00000</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          essayid        chars        words       commas  apostrophes  \\\n",
       "count  1332.00000  1332.000000  1332.000000  1332.000000  1332.000000   \n",
       "mean    905.27027  2101.745495   424.485736    14.667417     8.141141   \n",
       "std     526.68760   865.963750   171.873730    10.920781     6.124520   \n",
       "min       0.00000   169.000000    36.000000     0.000000     2.000000   \n",
       "25%     442.75000  1527.250000   310.000000     7.000000     4.000000   \n",
       "50%     914.50000  2029.500000   411.000000    13.000000     6.000000   \n",
       "75%    1369.75000  2613.500000   525.000000    21.000000    11.000000   \n",
       "max    1799.00000  6142.000000  1170.000000    72.000000    51.000000   \n",
       "\n",
       "       punctuations  avg_word_length    sentences    questions  \\\n",
       "count    1332.00000      1332.000000  1332.000000  1332.000000   \n",
       "mean        0.47973         4.939762    19.704204     1.222973   \n",
       "std         1.27168         0.231071    19.202731     1.847446   \n",
       "min         0.00000         2.231322     0.000000     0.000000   \n",
       "25%         0.00000         4.791679    13.000000     0.000000   \n",
       "50%         0.00000         4.946059    18.000000     1.000000   \n",
       "75%         0.00000         5.092938    24.000000     2.000000   \n",
       "max        26.00000         5.681429   642.000000    17.000000   \n",
       "\n",
       "       avg_word_sentence          POS  POS/total_words  prompt_words  \\\n",
       "count        1332.000000  1332.000000      1332.000000   1332.000000   \n",
       "mean           23.884687   420.596542         0.989935    198.913664   \n",
       "std            11.160020   170.985111         0.007308     82.729266   \n",
       "min             1.084112    35.647059         0.924771     14.000000   \n",
       "25%            19.142857   305.406284         0.987758    144.000000   \n",
       "50%            22.030331   406.982869         0.991572    193.000000   \n",
       "75%            26.048234   520.739458         0.994425    246.000000   \n",
       "max           303.000000  1158.984563         1.000000    669.000000   \n",
       "\n",
       "       prompt_words/total_words  synonym_words  synonym_words/total_words  \\\n",
       "count               1332.000000     1332.00000                1332.000000   \n",
       "mean                   0.469164      110.16967                   0.263846   \n",
       "std                    0.052466       43.96192                   0.038870   \n",
       "min                    0.288889       11.00000                   0.027299   \n",
       "25%                    0.435709       81.00000                   0.238423   \n",
       "50%                    0.465852      107.50000                   0.262872   \n",
       "75%                    0.500000      134.00000                   0.288277   \n",
       "max                    0.961207      355.00000                   0.465517   \n",
       "\n",
       "         unstemmed      stemmed        score  \n",
       "count  1332.000000  1332.000000  1332.000000  \n",
       "mean    468.987988   455.507508     3.427177  \n",
       "std     159.447449   155.751220     0.774275  \n",
       "min      48.000000    50.000000     1.000000  \n",
       "25%     361.000000   350.750000     3.000000  \n",
       "50%     463.000000   448.000000     3.000000  \n",
       "75%     581.000000   561.250000     4.000000  \n",
       "max     750.000000   750.000000     6.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EssayFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447    4\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_chars = EssayFeatures['chars'].max()\n",
    "EssayFeatures[EssayFeatures['chars'] == max_chars].score # using this line of code to check the score of the \n",
    "# student that contains the highest amount of characters in the essay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the data frame above, it is interesting to know that the mean for the number of characters is roughly 2100 and the mean score is approximately 3.5. This shows that the overall performance of students is quite good as the mean is greater than 3.0 ( assuming the passing score is 3.0 ). Besides that, the standard deviation for chars is the highest among all columns, it indicates that the spread or variation is tremendous for the number of characters. However, it is surprising to see that the maximum number of characters was around 6200, which is much more than the mean, I am wondering would the number of characters affect the score grading? Nevertheless, this student is still able to get a score that is above average ( which is 4 ) eventually. Hence, it is hard to say whether a long essay would be easy to get a high score or tend to make more mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions related to Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for supervised machine learning\n",
    "Supervised machine learning uses labeled data to train algorithms. It uses both input and output data to develop the prediction model and uses the data to train algorithms that can predict the output based on the new input data. The example problems for supervised machine learning are classification and regression. Classification is predicting the class label of a particular output using its input data whereas regression is predicting the continuous value. The examples of algorithms for regression and classification are linear regression and support vector machines sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for the notion of labelled data\n",
    "Labeled data refers to the data that is tagged with several (or one) labels to identify its features and also helps to distinguish a piece of data from another. Labeled data is useful for supervised machine learning as it is needed to help to train algorithms that are used to predict output from new input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for training and test datasets\n",
    "The training dataset is used to train a model to figure out the best algorithm that fits the model by using the data in the training dataset, and thus the model would be used to predict new data. The test dataset is used to evaluate the performance of the model that we had created by using the training dataset. All the data in the test dataset are valid as these data are specifically identified and hence it could provide an unbiased evaluation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EssayFeatures['Total_punctuations'] = EssayFeatures['commas'] + EssayFeatures['apostrophes'] + \\\n",
    "EssayFeatures['sentences'] + EssayFeatures['questions']\n",
    "EssayFeatures['Sum_of_POS_prompt_synonym'] = EssayFeatures['POS'] + EssayFeatures['prompt_words'] + \\\n",
    "EssayFeatures['synonym_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two new columns to improve the accuracy of the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the features and label\n",
    "feature_cols = ['Sum_of_POS_prompt_synonym','sentences','Total_punctuations','avg_word_sentence','unstemmed','stemmed'\n",
    "                ,'prompt_words/total_words','avg_word_length','words','chars']\n",
    "X = EssayFeatures[feature_cols] #  features\n",
    "y = EssayFeatures.score # label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features that would cause significant impact to the prediction of score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 3) \n",
    "# put random_state = 3 as it could makes the model to give higher qwk score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the train size as 0.80 and the test size as 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions related to Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for the difference between binary and multi-class classification\n",
    "Binary classification refers to classifying a piece of data into one of two classes, whereas multi-class classification, classifies a piece of data into one of more than two classes. An example of binary classification is spam email detection ( example given in the lecture slides ), the email can either be spam email or not spam email, since there are only two classes that could be used to assign email, hence it is a binary classification. An example of multi-class classification could be classifying the fruits into three classes ( assuming there are only three types of fruits ), for instance, apples, oranges, and grapes. Since the selected fruit can be assigned to one of the three classes, this is considered a multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the need for normalize data\n",
    "In machine learning, the range of the raw data usually varies widely, hence it is important to normalize data to make the object functions work on a proper feature scaling. In other words, normalizing data is changing the values of data ( usually refers to abnormal numeric data ) to make sure they are on a common scale, but their range remains the same. By doing so, the data can be visualized and analyzed and considered more useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe Support Vector Machine ( in relation to Linear Regression )\n",
    "Support Vector Machine (SVM) is considered as a supervising learning model in machine learning. SVM is usually used for classification and regression; it comes out with an algorithm that could be either a line or hyperplane that can classify the data, either binary or multi-class since it can be used to interpret linear problems ( and also non-linear problems ). The advantage of using SVM is that this model is efficient when solving the problem with high-dimension spaces.\n",
    "\n",
    "The difference between Support Vector Machine and Linear Regression is that SVM always finds the best line or hyperplane ( as its algorithm is more complex ) to separate data into different classes and minimize the error. Whereas linear regression is classifying the data based on a dependent variable and one ( or more ) independent variable to find out the relationship using the linear approach, and its algorithm is less complex compared with SVM. Another difference is that SVM is usually used to solve classification and regression problems whereas linear regression is used to solve classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for the kernel in SVM/SVR\n",
    "In support vector machine algorithms, it classifies data into different classes, however, not every data is separable, hence a kernel is needed in this situation. A kernel is a function that can transform the non-separable data into separable data, and hence no matter how complex the data is, the kernel can help to separate it based on the labels and eventually figure out the algorithm. In SVM/SVR, there are several types of the kernel, such as 'linear', 'poly', 'RBF', and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best situation for each kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* linear - if the dataset is linearly separable, the linear kernel would be the first choice and also because the complexity to train the model would be lower than the RBF kernel\n",
    "* poly - poly kernel is used when there is a non-linear relationship between features and the complexity is lower than RBF kernel but generally the accuracy is also lower compared to RBF kernel\n",
    "* RBF - if the dataset is not linearly separable and hope to have a highly accurate model, then we should consider using RBF kernel, however, the complexity would be high\n",
    " \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel='rbf', epsilon = 0.3, C = 3.1) # editing the parameter of the model to improve the model\n",
    "# assigned eplison = 0.3 and C = 3.1 as these parameters lead to higher qwk score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=3.1, epsilon=0.3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.fit(X_train, y_train)  # build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why I use SVR instead of SVC? \n",
    "In this assignment, I had decided to use SVR to create my model instead of SVC. The reason is that SVR would give an appropriate line that suits the data. Although the SVR model would give continuous values as prediction, I can still round the values to an integer. In my point of view, I think that using SVR is better than SVC in this situation, as SVR could figure out the non-linearity of the features and label and therefore it would provide a more comprehensive predictive model. Unlike SVC, I think it would not perform well enough when there is a huge dataset that may contain a lot of noise, hence it could not separate the data correctly and its prediction might not be as accurate as SVR in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to predict the score for the testing dataset to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.34615232, 3.75697   , 3.12825449, 3.92484775, 3.56959954,\n",
       "       3.54139104, 4.41174661, 3.59066067, 3.84406658, 2.94595027])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10] # print the first 10 prediction values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = round(y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the prediction values are all float numbers, I had to convert them to an integer by rounding all the values using a for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  0,  0,  0,  0],\n",
       "       [ 0, 16,  8,  0,  0,  0],\n",
       "       [ 0,  5, 79, 20,  0,  0],\n",
       "       [ 0,  0, 32, 87,  0,  0],\n",
       "       [ 0,  0,  0, 14,  2,  0],\n",
       "       [ 0,  0,  0,  1,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first argument is true values, second argument is predicted values\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the confusion matrix by using the y_test and y_pred as a parameter to check the performance of the model.\n",
    "The first argument must be true values and the second argument must be the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a better confusion matrix \n",
    "labels = [1,2,3,4,5,6]\n",
    "ax = plt.subplot()\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "# first argument is true values and second argument is the predicted values\n",
    "sns.heatmap(cm, annot = True, ax = ax)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix provides better visualization of the performance of the SVR model with clear labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation on the confusion matrix \n",
    "\n",
    " * aij indicates the cell that at ith row and jth column\n",
    "\n",
    "Based on the confusion matrix above, a12, a64, and a65 show that my model did not successfully predict the essay with scores 1 and 6 correctly. Hence, the classification report states that the precision for predicting scores 1 and 6 is 0.00. Among all the classes, the model did the best when predicting the essay with scores 2 and 4. The precision for these two classes was almost the same, which are 0.70 and 0.71 for scores 2 and 4 respectively. It is interesting to know that the precision for the prediction of scores 3 and 5 are also almost the same, which is 0.66 and 0.67 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.70      0.67      0.68        24\n",
      "           3       0.66      0.76      0.71       104\n",
      "           4       0.71      0.73      0.72       119\n",
      "           5       0.67      0.12      0.21        16\n",
      "           6       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.69       267\n",
      "   macro avg       0.46      0.38      0.39       267\n",
      "weighted avg       0.68      0.69      0.67       267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy Kuah Jia Chen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of the warning\n",
    "Based on my understanding, I think the reason for the warning to happen is because the model did not predict any data for certain labels, for example, 1 and 6. Hence, when calculating the precision and f1-score, zero division may occur during the calculation, therefore precision and f1-score for these labels ( which is 1 and 6 ) is set to 0.0 and this warning is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6891385767790262\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score of my model\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the classification report above, shows that the accuracy of this model is around 0.69. Besides that, there is much information also displayed in this report, such as the precision of each score, the f1-score for each score, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Weighted Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7019470404984423"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "qwk = cohen_kappa_score(y_test, y_pred, weights = \"quadratic\") \n",
    "qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for Quadratic Weighted Kappa\n",
    "Quadratic Weighted Kappa is used to measure the agreement between two ratings, in this case, it is measuring the agreement between the actual score of the dataset and the prediction score. QWK can vary from 0 to 1.0. Quadratic Weighted Kappa is kind of like the value of accuracy for the classifier, it tells people how good your classifier's performance is. For my classifier, the QWK is 0.70. \n",
    "\n",
    "Usually, a 0.6 -0.8 qwk score would be considered a good qwk score, if the qwk score is in the range of 0.8 - 1.0, the model is already considered almost perfect. If the qwk was below 0.6, the model needs some improvement. If the model has a negative qwk score, it indicates the model has no agreement with the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quadratic weighted kappa for this model is around 0.70."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read \"FIT1043-Essay-Features-Submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>4332</td>\n",
       "      <td>900</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4.813333</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>893.988852</td>\n",
       "      <td>0.993321</td>\n",
       "      <td>392</td>\n",
       "      <td>0.435556</td>\n",
       "      <td>196</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>1465</td>\n",
       "      <td>280</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.232143</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>278.321343</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>131</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>51</td>\n",
       "      <td>0.182143</td>\n",
       "      <td>339</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>1696</td>\n",
       "      <td>325</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.218462</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>17.105263</td>\n",
       "      <td>321.316770</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>178</td>\n",
       "      <td>0.547692</td>\n",
       "      <td>92</td>\n",
       "      <td>0.283077</td>\n",
       "      <td>352</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "      <td>2640</td>\n",
       "      <td>555</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.756757</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19.821429</td>\n",
       "      <td>551.989150</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>228</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>107</td>\n",
       "      <td>0.192793</td>\n",
       "      <td>632</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>2844</td>\n",
       "      <td>596</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.771812</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>593.658810</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>279</td>\n",
       "      <td>0.468121</td>\n",
       "      <td>138</td>\n",
       "      <td>0.231544</td>\n",
       "      <td>626</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1623   4332    900      28           13             0         4.813333   \n",
       "1     1143   1465    280      11            3             1         5.232143   \n",
       "2      660   1696    325      17            2             0         5.218462   \n",
       "3     1596   2640    555      20           17             0         4.756757   \n",
       "4      846   2844    596      33            4             1         4.771812   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         39          1          23.076923  893.988852         0.993321   \n",
       "1         14          3          20.000000  278.321343         0.994005   \n",
       "2         19          1          17.105263  321.316770         0.988667   \n",
       "3         28          0          19.821429  551.989150         0.994575   \n",
       "4         24          9          24.833333  593.658810         0.996072   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           392                  0.435556            196   \n",
       "1           131                  0.467857             51   \n",
       "2           178                  0.547692             92   \n",
       "3           228                  0.410811            107   \n",
       "4           279                  0.468121            138   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  \n",
       "0                   0.217778        750      750  \n",
       "1                   0.182143        339      316  \n",
       "2                   0.283077        352      337  \n",
       "3                   0.192793        632      605  \n",
       "4                   0.231544        626      607  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KaggleSubmission = pd.read_csv(r\"C:\\Users\\Andy Kuah Jia Chen\\Downloads\\FIT1043 Assignments\\Prediction-Of-Essay_Scores\\data\\FIT1043-Essay-Features-Submission.csv\")\n",
    "KaggleSubmission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleSubmission['Total_punctuations'] = KaggleSubmission['commas'] + KaggleSubmission['apostrophes'] + \\\n",
    "KaggleSubmission['sentences'] + KaggleSubmission['questions']\n",
    "KaggleSubmission['Sum_of_POS_prompt_synonym'] = KaggleSubmission['POS'] + KaggleSubmission['prompt_words'] + \\\n",
    "KaggleSubmission['synonym_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Sum_of_POS_prompt_synonym','sentences','Total_punctuations','avg_word_sentence','unstemmed','stemmed'\n",
    "                ,'prompt_words/total_words','avg_word_length','words','chars']\n",
    "X = KaggleSubmission[feature_cols] #  features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = svr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to do the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.08493773, 3.32313312, 3.55926438, 3.64299129, 3.8292744 ,\n",
       "       3.40488482, 3.29344848, 3.42672987, 3.23727063, 2.54565545])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new_pred[0:10] # print the first 20 prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_new_pred)):  # rounding all prediction values \n",
    "    y_new_pred[i] = round(y_new_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the prediction values are all float numbers, I had to convert them to an integer by rounding all the values using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 4, 4, 4, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_pred = []\n",
    "for i in range(len(y_new_pred)):  # convert all prediction values from float to integer\n",
    "    kaggle_pred.append(int(y_new_pred[i])) # example, from 4.0 to 4\n",
    "kaggle_pred[0:10] # print the first 10 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read \"99999999-YourName-1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  score\n",
       "0     1623    NaN\n",
       "1     1143    NaN\n",
       "2      660    NaN\n",
       "3     1596    NaN\n",
       "4      846    NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubmissionFile = pd.read_csv(r\"C:\\Users\\Andy Kuah Jia Chen\\Downloads\\FIT1043 Assignments\\Prediction-Of-Essay_Scores\\data\\99999999-YourName-1.csv\")\n",
    "SubmissionFile.head() # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the predicted score to the score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionFile['score'] = kaggle_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1596</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>846</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essayid  score\n",
       "0     1623      4\n",
       "1     1143      3\n",
       "2      660      4\n",
       "3     1596      4\n",
       "4      846      4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubmissionFile.head() # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the two columns to a new CSV file for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = SubmissionFile\n",
    "df.to_csv(r\"C:\\Users\\Andy Kuah Jia Chen\\Downloads\\FIT1043 Assignments\\Prediction-Of-Essay_Scores\\data\\32286988-KuahJiaChen.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, this assignment provides clear visualization and a great experience for me to understand how predictive analytics works. I had to use SVR as the model to do prediction. In my opinion, the most difficult part is to figure out the best features used for prediction. The feature columns are one of the major factors that affect the performance of the model significantly, hence the right essay features would be extremely important to improve the model. Besides that, I also realized the importance of the confusion matrix and classification report, as these enable people to visualize the performance of the model in a much more detailed way. In this assignment, I had a better understanding of the meaning of supervised learning, the notion of labeled data, the difference between training and testing dataset, the difference between binary and multi-class classification, what is Support Vector Machine/Regression, and the kernel of SVM/SVR. I also had the chance to experience the Kaggle competition due to this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Raschka, S. (2016). How to Select Support Vector Machine Kernels. KDnuggets. https://www.kdnuggets.com/2016/06/select-support-vector-machine-kernels.html\n",
    "2. Wikipedia contributors. (2019, October 2). Polynomial kernel. Wikipedia. https://en.wikipedia.org/wiki/Polynomial_kernel#:%7E:text=In%20machine%20learning%2C%20the%20polynomial,learning%20of%20non%2Dlinear%20models.\n",
    "3. Awasthi, S. (2020, December 17). Seven Most Popular SVM Kernels. Dataaspirant. https://dataaspirant.com/svm-kernels/#t-1608054630718"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
